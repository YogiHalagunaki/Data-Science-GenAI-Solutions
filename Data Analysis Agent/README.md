# Data Cleaning Agent

A modular and extensible Python-based agent for intelligent **data cleaning**, **normalization**, and **preprocessing** of messy tabular data using custom logic and LLM-enhanced pipelines.

---

## üöÄ Features

- ‚úÖ Automatic column type classification (`country`, `name`, `numeric`, `address`)
- üåç Standardizes country names to ISO 3-letter codes (e.g., "USA" ‚Üí "USA")
- üë§ Cleans and formats names (removes titles, trims whitespace, proper casing)
- üî¢ Removes outliers from numeric columns using z-score
- üè¢ Normalizes address formats with common replacements (e.g., "St." ‚Üí "Street")
- üìÖ Flexible handling of inconsistent date formats (extendable)
- ü§ñ LLM-ready architecture via Azure OpenAI and `LangGraph` workflow engine
- üì¶ Easy CSV or Excel I/O

---

## üìÅ Project Structure

```bash
.
‚îú‚îÄ‚îÄ example_usage.py # Test script for loading and cleaning sample data
‚îú‚îÄ‚îÄ data_cleaning_agent.py# Core logic for data cleaning agent
‚îú‚îÄ‚îÄ .env # Environment variables for Azure OpenAI
‚îú‚îÄ‚îÄ cleaned_data.csv # Output file with cleaned data
‚îî‚îÄ‚îÄ README.md # This file


```
---

## üß† How It Works

### 1. `DataCleaningAgent` Class
Handles the complete cleaning workflow including:

- Column classification
- Country normalization using `pycountry` + `fuzzywuzzy`
- Name/address normalization
- Numeric outlier detection with `scipy.stats.zscore`

### 2. LangGraph Workflow

The cleaning process is defined as a directed graph:

```mermaid
graph LR
  analyze --> clean_countries --> clean_addresses --> clean_names --> clean_numeric

```
---
## üõ†Ô∏è Setup Instructions

### 1. Clone the Repository
```bash 
# Clone the repo
git lone https://github.com/YogiHalagunaki/Data-Science-GenAI-Solutions.git
cd Data Analysis Agent


```
### 2. Install dependencies
```bash 
pip install -r requirements.txt

```
### 3. Configure Environment Variables
```bash
AZURE_OPENAI_API_KEY=your_key_here
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-XX-XX

```
### 4. Run the Sample Cleaning Script
```bash
python example_usage.py

```
## üß™ Sample Output
```plaintext
Starting data cleaning process...
responce::::::::: Identified country column: location
responce::::::::: Identified name column: full_name
responce::::::::: Identified numeric column: age
responce::::::::: Identified numeric column: salary
responce::::::::: Normalized country names in column: location
responce::::::::: Normalized names in column: full_name
responce::::::::: Removed outliers from column: age
responce::::::::: Removed outliers from column: salary

```
---
## üß© Extensibility
* You can extend the agent by:

* Adding custom logic to _normalize_* methods

* Adding new node functions and updating create_workflow()

* Integrating LLM-based decisions (currently scaffolded for Azure OpenAI)

--- 

## üôå Acknowledgments
Built with:

- `LangGraph`

- `Azure OpenAI`

- `pandas`

- `scipy`

- `fuzzywuzzy`

```

## üôã Author

**Yogi Halagunaki**  
GitHub: [@YogiHalagunaki](https://github.com/YogiHalagunaki)  
Email: halagunakiyogi@gmil.com  
Location: India 

