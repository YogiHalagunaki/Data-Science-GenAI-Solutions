# Data Cleaning Agent

A modular and extensible Python-based agent for intelligent **data cleaning**, **normalization**, and **preprocessing** of messy tabular data using custom logic and LLM-enhanced pipelines.

---

## ğŸš€ Features

- âœ… Automatic column type classification (`country`, `name`, `numeric`, `address`)
- ğŸŒ Standardizes country names to ISO 3-letter codes (e.g., "USA" â†’ "USA")
- ğŸ‘¤ Cleans and formats names (removes titles, trims whitespace, proper casing)
- ğŸ”¢ Removes outliers from numeric columns using z-score
- ğŸ¢ Normalizes address formats with common replacements (e.g., "St." â†’ "Street")
- ğŸ“… Flexible handling of inconsistent date formats (extendable)
- ğŸ¤– LLM-ready architecture via Azure OpenAI and `LangGraph` workflow engine
- ğŸ“¦ Easy CSV or Excel I/O

---

## ğŸ“ Project Structure

```plaintext
.
â”œâ”€â”€ test.py # Test script for loading and cleaning sample data
â”œâ”€â”€ data_cleaning_agent.py# Core logic for data cleaning agent
â”œâ”€â”€ .env # Environment variables for Azure OpenAI
â”œâ”€â”€ cleaned_data.csv # Output file with cleaned data
â””â”€â”€ README.md # This file


```
---

## ğŸ§  How It Works

### 1. `DataCleaningAgent` Class
Handles the complete cleaning workflow including:

- Column classification
- Country normalization using `pycountry` + `fuzzywuzzy`
- Name/address normalization
- Numeric outlier detection with `scipy.stats.zscore`

### 2. LangGraph Workflow
The cleaning process is defined as a graph pipeline:

---
## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository
```bash 
# Clone the repo
git lone https://github.com/YogiHalagunaki/Data-Science-GenAI-Solutions.git
cd Data Analysis Agent


```
### 2. Install dependencies
```bash 
pip install -r requirements.txt

```
### 3. Configure Environment Variables
```bash
AZURE_OPENAI_API_KEY=your_key_here
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-XX-XX

```
### 4. Run the Sample Cleaning Script
```bash
python example_usage.py

```
## ğŸ§ª Sample Output
```plaintext
Starting data cleaning process...
responce::::::::: Identified country column: location
responce::::::::: Identified name column: full_name
responce::::::::: Identified numeric column: age
responce::::::::: Identified numeric column: salary
responce::::::::: Normalized country names in column: location
responce::::::::: Normalized names in column: full_name
responce::::::::: Removed outliers from column: age
responce::::::::: Removed outliers from column: salary

```
---
## ğŸ§© Extensibility
* You can extend the agent by:

* Adding custom logic to _normalize_* methods

* Adding new node functions and updating create_workflow()

* Integrating LLM-based decisions (currently scaffolded for Azure OpenAI)

--- 

## ğŸ™Œ Acknowledgments
Built with:

* LangGraph

* Azure OpenAI

* pandas

* scipy

* fuzzywuzzy

```

## ğŸ™‹ Author

**Yogi Halagunaki**  
GitHub: [@YogiHalagunaki](https://github.com/YogiHalagunaki)  
Email: halagunakiyogi@gmil.com  
Location: India 

